#!/usr/bin/env python
import json

from transformers import AutoModelForCausalLM, AutoTokenizer, BlenderbotTokenizer, BlenderbotForConditionalGeneration
import torch
from bottle import Bottle, request, response

# select model
# -- DialoGPT models --
# MNAME = "Lovery/Aqua"
# MNAME = "microsoft/DialoGPT-small"
# MNAME = "microsoft/DialoGPT-medium"
MNAME = "microsoft/DialoGPT-large"
# MNAME = "deepparag/DumBot"
# MNAME = "abhiramtirumala/DialoGPT-sarcastic"
# MNAME = "Kryptone/monikAI"
# MNAME = "Kryptone/monikAI-Unstable"
# MNAME = "luca-martial/DialoGPT-Elon"
# MNAME = "S34NtheGuy/DialoGPT-medium-Glass_Of_Water"
# MNAME = "transfaeries/DialoGPT-medium-Discord-1.0"
# -- blenderbot models --
# MNAME = "facebook/blenderbot-400M-distill"
# MNAME = "facebook/blenderbot-1B-distill"
# MNAME = "chujiezheng/blenderbot-400M-ESC"

# select model type
MODEL_TYPE = "DialoGPT"
# MODEL_TYPE = "blenderbot"

# initialize model and tokenizer
if MODEL_TYPE == "DialoGPT":
    tokenizer = AutoTokenizer.from_pretrained(MNAME)
    model = AutoModelForCausalLM.from_pretrained(MNAME)
elif MODEL_TYPE == "blenderbot":
    model = BlenderbotForConditionalGeneration.from_pretrained(MNAME)
    tokenizer = BlenderbotTokenizer.from_pretrained(MNAME)
else:
    raise Exception

# initialize bottle web framework
app = Bottle()

# chat history storage for specific chat ids (usually user id)
chat_history = {}

# chat route
@app.route("/chat", method="POST")
def do_chat():
    print(f"{request.json['id']}: {request.json['text']}")

    # sanity fixes
    if request.json['id'] not in chat_history:
        reset_chat_history(request.json["id"])

    reply = ""
    if MODEL_TYPE == "DialoGPT":
        # encode user input
        user_input_ids = tokenizer.encode(request.json["text"] + tokenizer.eos_token, return_tensors="pt")

        # generate output with history clamped to 1000 tokens
        model_input_ids = torch.cat([chat_history[request.json["id"]], user_input_ids], dim=-1) if chat_history[request.json["id"]] is not None else user_input_ids
        try:
            chat_history[request.json["id"]] = model.generate(
                model_input_ids,
                max_length=1000,
                pad_token_id=tokenizer.eos_token_id,
                num_beams=3,
                no_repeat_ngram_size=4,
                do_sample=False,
                top_k=80,
                top_p=0.9,
                temperatue=0.8,
                repetition_penaly=1.2,
            )
        except Exception:
            reset_chat_history(request.json["id"])
            print(f"Force reset history for: {request.json['id']}")
            return json.dumps({ "error": "fr" })

        # decode reply
        reply = tokenizer.decode(chat_history[request.json["id"]][:, model_input_ids.shape[-1]:][0], skip_special_tokens=True).strip()
    elif MODEL_TYPE == "blenderbot":
        chat_history[request.json["id"]].append(request.json["text"])

        if len(chat_history[request.json["id"]]) > 5:
            chat_history[request.json["id"]].pop(0)
            chat_history[request.json["id"]].pop(0)

        # encode user input
        uttr = "    ".join(chat_history[request.json["id"]])
        model_input_ids = tokenizer([uttr], return_tensors="pt")

        # generate output
        try:
            reply_ids = model.generate(**model_input_ids)
        except Exception:
            reset_chat_history(request.json["id"])
            print(f"Force reset history for: {request.json['id']}")
            return json.dumps({ "error": "fr" })

        # decode reply
        reply = tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0].strip()
        chat_history[request.json["id"]].append(reply)

    print(f"wozey: {reply}")

    # send back
    return json.dumps({ "reply": reply })


# reset chat history route
@app.route("/reset", method="POST")
def do_reset():
    print(f"Reset history for: {request.json['id']}")

    reset_chat_history(request.json["id"])

    return


def reset_chat_history(uid):
    if MODEL_TYPE == "DialoGPT":
        chat_history[uid] = None
    elif MODEL_TYPE == "blenderbot":
        chat_history[uid] = []

# CORS Header
@app.route('/<:re:.*>', method='OPTIONS')
def cors():
    pass


headers = ['Origin', 'Accept', 'Content-Type',
           'X-Requested-With', 'X-CSRF-Token',
           'Authorization']
HEADERS = ', '.join((headers + [h.lower() for h in headers]))


def apply_cors():
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = 'POST'
    response.headers['Access-Control-Allow-Headers'] = HEADERS


app.add_hook('after_request', apply_cors)
app.run(host="::", port=6769)