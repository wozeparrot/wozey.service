#!/usr/bin/env python
from gevent import monkey; monkey.patch_all()

import json
import gc
from abc import ABC, abstractmethod
from typing import Any
import operator

from transformers import GPT2LMHeadModel, GPTNeoForCausalLM, GPT2TokenizerFast, BlenderbotForConditionalGeneration, BlenderbotTokenizer
from transformers import pipeline
import torch

import gevent
from gevent.lock import RLock
from bottle import Bottle, request, response


# --- CHAT HISTORY ---
class ChatHistory:
    def __init__(self):
        self.chat_history = {}
        self.lock = RLock()

    def add_user(self, uid, text) -> None:
        with self.lock:
            self.chat_history[uid]["user"].append(text)

    def add_bot(self, uid, text: str) -> None:
        with self.lock:
            self.chat_history[uid]["bot"].append(text)

    def add_prefix(self, uid: int, text: str) -> None:
        with self.lock:
            self.chat_history[uid]["prefix"].append(text)

    def gen_model_input(self, uid: int, text: str, agent: Any) -> str:
        with self.lock:
            prefix = self.chat_history[uid]["prefix"]
            if len(prefix) > 0:
                prefix = agent.seperator.join(prefix) + agent.seperator
            else:
                prefix = ""

            current_tokens = agent.tokenizer(prefix + text)["input_ids"]
            ch_for_current_turn = []
            num_ch_tokens = len(current_tokens)

            for u, m in zip(reversed(self.chat_history[uid]["user"]), reversed(self.chat_history[uid]["bot"])):
                ch = u + agent.seperator + m + agent.seperator
                tokens = agent.tokenizer(ch)["input_ids"]

                num_ch_tokens += len(tokens)
                if num_ch_tokens < agent.maxlen:
                    ch_for_current_turn.append(ch)
                else:
                    break
    
            ch_for_current_turn = list(reversed(ch_for_current_turn))
            return prefix + "".join(ch_for_current_turn) + text

    def reset(self, uid: int) -> None:
        with self.lock:
            self.chat_history[uid] = {
                "user": [],
                "bot": [],
                "prefix": [],
            }
    
    def is_empty(self, uid: int) -> bool:
        return len(self.chat_history[uid]["user"]) == 0 and len(self.chat_history[uid]["bot"]) == 0 and len(self.chat_history[uid]["prefix"]) == 0


# --- ChatAgents ---
class ChatAgent(ABC):
    def __init__(self, seperator: str, maxlen: int, model: Any, tokenizer: Any):
        self.seperator = seperator
        self.maxlen = maxlen
        self.model = model
        self.tokenizer = tokenizer
    
    @abstractmethod
    def init(self, ch: ChatHistory, uid: int, user: str) -> None:
        raise NotImplemented
    
    @abstractmethod
    def preprocess(self, text: str, user: str) -> str:
        raise NotImplemented

    @abstractmethod
    def generate(self, text: str, user: str) -> str:
        raise NotImplemented


class DialoGPTChatAgent(ChatAgent):
    def __init__(self, name: str):
        model = GPT2LMHeadModel.from_pretrained(name)

        super().__init__(
            seperator="<|endoftext|>",
            maxlen=128,
            model=model.eval(),
            tokenizer=GPT2TokenizerFast.from_pretrained(name),
        )
    
    def init(self, ch: ChatHistory, uid: int, user: str) -> None:
        prefixes = [
            f"My name is {user} and your name is wozey.",
            f"Hello {user}. I am wozey.",
        ]

        for prefix in prefixes:
            ch.add_prefix(uid, prefix)
    
    def preprocess(self, text: str, user: str) -> str:
        return text + self.seperator
    
    def generate(self, text: str, user: str) -> str:
        input_ids = self.tokenizer(
            text=text,
            return_tensors="pt",
        )["input_ids"]

        output_ids = self.model.generate(
            input_ids=input_ids,
            pad_token_id=self.tokenizer.eos_token_id,
            max_length=self.maxlen * 2,
            num_beams=5,
            top_k=20,
            top_p=None,
            no_repeat_ngram_size=4,
            length_penalty=1.35,
            repetition_penalty=2.0,
            use_cache=True,
        )

        return self.tokenizer.decode(output_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True).strip()


class GPTNeoChatAgent(ChatAgent):
    def __init__(self, name: str):
        model = GPTNeoForCausalLM.from_pretrained(name)

        super().__init__(
            seperator=" ",
            maxlen=256,
            model=model.eval(),
            tokenizer=GPT2TokenizerFast.from_pretrained(name),
        )
    
    def init(self, ch: ChatHistory, uid: int, user: str) -> None:
        prefixes = [
            f"{user} and wozey start talking.",
            f"I'm {user} and you are wozey!",
        ]

        for prefix in prefixes:
            ch.add_prefix(uid, prefix)
    
    def preprocess(self, text: str, user: str) -> str:
        return f"{user}: {text}" + self.seperator + "wozey:"
    
    def generate(self, text: str, user: str):
        input_ids = self.tokenizer(
            text=text,
            max_length=self.maxlen,
            truncation=True,
            return_tensors="pt",
        )["input_ids"]

        output_ids = self.model.generate(
            input_ids=input_ids,
            pad_token_id=self.tokenizer.eos_token_id,
            max_length=input_ids.size()[-1] + self.maxlen // 2,
            early_stopping=True,
            num_beams=6,
            num_beam_groups=2,
            top_k=20,
            top_p=None,
            no_repeat_ngram_size=4,
            diverse_penalty=1.5,
            length_penalty=0.7,
            repetition_penalty=2.0,
            use_cache=True,
        )

        reply = self.tokenizer.decode(
            output_ids[:, input_ids.shape[-1]:][0],
            skip_special_tokens=True,
        ).strip()

        for escape in [
            f"{user}:",
            f"{user.upper()}:",
            f"{user.lower()}:",
            "wozey:",
            "WOZEY:",
            "Wozey:",
        ]:
            reply = reply.replace(escape, "\n")
        
        return reply.split("\n")[0].strip()


class BlenderBotChatAgent(ChatAgent):
    def __init__(self, name: str):
        model = BlenderbotForConditionalGeneration.from_pretrained(name)

        super().__init__(
            seperator="    ",
            maxlen=128,
            model=model.eval(),
            tokenizer=BlenderbotTokenizer.from_pretrained(name),
        )
    
    def init(self, ch: ChatHistory, uid: int, user: str) -> None:
        prefixes = [
            f"My name is {user} and your name is wozey.",
            f"Hello {user}, I am wozey.",
        ]

        for prefix in prefixes:
            ch.add_prefix(uid, prefix)

    def preprocess(self, text: str, user: str) -> str:
        return text + self.seperator
    
    def generate(self, text: str, user: str) -> str:
        input_ids = self.tokenizer(
            text=text,
            return_tensors="pt",
        )["input_ids"]

        output_ids = self.model.generate(
            input_ids=input_ids,
            pad_token_id=self.tokenizer.eos_token_id,
            max_length=self.maxlen * 2,
            num_beams=5,
            top_k=None,
            top_p=None,
            no_repeat_ngram_size=4,
            length_penalty=0.65,
            repetition_penalty=2.0,
            use_cache=True,
        )

        return self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()


# --- CONFIG ---
# -- Chat Agent Selection --
# CHAT_AGENT = DialoGPTChatAgent("Lovery/Aqua")
# CHAT_AGENT = DialoGPTChatAgent("microsoft/DialoGPT-small")
# CHAT_AGENT = DialoGPTChatAgent("microsoft/DialoGPT-medium")
# CHAT_AGENT = DialoGPTChatAgent("microsoft/DialoGPT-large")
# CHAT_AGENT = DialoGPTChatAgent("abhiramtirumala/DialoGPT-sarcastic")
# CHAT_AGENT = DialoGPTChatAgent("Kryptone/monikAI")
# CHAT_AGENT = DialoGPTChatAgent("Kryptone/monikAI-Unstable")
# CHAT_AGENT = DialoGPTChatAgent("luca-martial/DialoGPT-Elon")
CHAT_AGENT = DialoGPTChatAgent("S34NtheGuy/DialoGPT-medium-Glass_Of_Water")
# CHAT_AGENT = DialoGPTChatAgent("transfaeries/DialoGPT-medium-Discord-1.0")
# CHAT_AGENT = DialoGPTChatAgent("deepparag/Aeona")
# CHAT_AGENT = GPTNeoChatAgent("EleutherAI/gpt-neo-125M")
# CHAT_AGENT = GPTNeoChatAgent("EleutherAI/gpt-neo-1.3B")
# CHAT_AGENT = BlenderBotChatAgent("facebook/blenderbot-400M-distill")

# -- Toxic Agent Selection --
TOXIC_AGENT = pipeline("text-classification", model="unitary/unbiased-toxic-roberta", function_to_apply="sigmoid", return_all_scores=True)


# --- MAIN ---
# initialize bottle web framework
app = Bottle()

# get threadpool
pool = gevent.get_hub().threadpool

# initialize chat history
chat_history = ChatHistory()

# initialize locks
chat_lock = RLock()
toxic_lock = RLock()

# chat route
@app.route("/chat", method="POST")
def do_chat():
    with chat_lock:
        # cleanup request data
        uid = request.json["id"]
        user = request.json["user"]
        uin = request.json["text"].strip()
        print(f"[chat][{uid}, {user}]: {uin}")

        # sanity fixes
        if uid not in chat_history.chat_history:
            chat_history.reset(uid)
    
        # init agent for user
        if chat_history.is_empty(uid):
            CHAT_AGENT.init(chat_history, uid, user)

        # generate input for model
        model_input = chat_history.gen_model_input(uid, CHAT_AGENT.preprocess(uin, user), CHAT_AGENT)
        chat_history.add_user(uid, uin)

        # generate output from model
        reply = pool.spawn(CHAT_AGENT.generate, model_input, user).get()
        chat_history.add_bot(uid, reply)
        print(f"[chat][wozey]: {reply}")

        gc.collect()

        # send back
        return json.dumps({ "reply": reply })


# reset chat history route
@app.route("/reset_ch", method="POST")
def do_reset_ch():
    with chat_lock:
        print(f"Reset history for: {request.json['id']}")

        chat_history.reset(request.json["id"])


# toxic analysis route
@app.route("/toxic", method="POST")
def do_toxic():
    if True:
        user = request.json["user"]
        text = request.json["text"].strip()
        print(f"[toxic][{user}]: {text}")

        results = pool.spawn(TOXIC_AGENT, text).get()
        results = {res["label"]: res["score"] for res in results[0]}
        print({k: round(results[k], 3) for k in results})

        return json.dumps(results)


# run
gc.collect()
app.run(server="gevent", host="::", port=6769)
